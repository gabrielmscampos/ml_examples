{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 16:20:29.449164: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-06 16:20:29.459467: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741274429.471741   46654 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741274429.475215   46654 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-06 16:20:29.487936: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PreprocessingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        min_val = tf.reduce_min(inputs, axis=0)\n",
    "        max_val = tf.reduce_max(inputs, axis=0)\n",
    "        normalized_inputs = tf.where(\n",
    "            max_val - min_val != 0,\n",
    "            (inputs - min_val) / (max_val - min_val + 1e-8),\n",
    "            tf.zeros_like(inputs),\n",
    "        )\n",
    "        return normalized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    \"\"\"Autoencoder that reconstruct METSig distributions and flag anomalies\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: tuple[int], l2_lambda: float):\n",
    "        input_layer = tf.keras.Input(shape=input_shape)\n",
    "        prep_layer = PreprocessingLayer()(input_layer)\n",
    "        encoded = tf.keras.layers.Dense(18, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_lambda))(prep_layer)\n",
    "        encoded = tf.keras.layers.Dense(8, activation=\"sigmoid\")(encoded)\n",
    "        decoded = tf.keras.layers.Dense(18, activation=\"sigmoid\")(encoded)\n",
    "        decoded = tf.keras.layers.Dense(input_shape[0], activation=\"sigmoid\")(decoded)\n",
    "        self.model = tf.keras.models.Model(input_layer, decoded)\n",
    "\n",
    "        # Since `avg_mse` shares the same layers (prep_layer and decoded) as the `self.model`\n",
    "        # this `self.stripped_model` doesn't need to be trained\n",
    "        avg_mse = tf.keras.losses.MSE(prep_layer, decoded)  # Compute the mean squared error for each row in the inputs\n",
    "        self.stripped_model = tf.keras.models.Model(input_layer, avg_mse)\n",
    "\n",
    "    def compile(self):\n",
    "        self.model.compile(optimizer=\"adam\", loss=[\"mse\"], metrics=[\"mse\"])\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def predict(self, inputs: np.ndarray):\n",
    "        return self.model.predict(inputs)\n",
    "\n",
    "    def fit(self, inputs: np.ndarray, batch_size: int, epochs: int):\n",
    "        targets = PreprocessingLayer()(inputs)\n",
    "        history: tf.keras.callbacks.History = self.model.fit(\n",
    "            inputs, targets, batch_size=batch_size, epochs=epochs\n",
    "        )\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1940., 1987.,  670., ...,    0.,    0.,    0.],\n",
       "       [1869., 1872.,  714., ...,    0.,    0.,    0.],\n",
       "       [1819., 1924.,  672., ...,    0.,    0.,    0.],\n",
       "       ...,\n",
       "       [1171.,  989.,  293., ...,    0.,    0.,    0.],\n",
       "       [1225.,  960.,  289., ...,    0.,    0.,    0.],\n",
       "       [1190.,  994.,  257., ...,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load(\"../data/data_386642.npy\")\n",
    "train_label = np.load(\"../data/label_386642.npy\")\n",
    "\n",
    "# We want to feed the Autoencoder with GOOD data, so we filter the data by the label == 1\n",
    "train_data = train_data[train_label == 1]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-06 16:20:30.969663: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ preprocessing_layer             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PreprocessingLayer</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">162</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">969</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ preprocessing_layer             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mPreprocessingLayer\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m162\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)             │           \u001b[38;5;34m969\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,219</span> (8.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,219\u001b[0m (8.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,219</span> (8.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,219\u001b[0m (8.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ae = Autoencoder(input_shape=(51,), l2_lambda=1e-4)\n",
    "ae.compile()\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2065 - mse: 0.1953  \n",
      "Epoch 2/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1920 - mse: 0.1829 \n",
      "Epoch 3/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1793 - mse: 0.1715 \n",
      "Epoch 4/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1665 - mse: 0.1604 \n",
      "Epoch 5/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1547 - mse: 0.1496 \n",
      "Epoch 6/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1438 - mse: 0.1396 \n",
      "Epoch 7/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1335 - mse: 0.1300 \n",
      "Epoch 8/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1234 - mse: 0.1205 \n",
      "Epoch 9/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1139 - mse: 0.1115 \n",
      "Epoch 10/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1054 - mse: 0.1036 \n",
      "Epoch 11/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0974 - mse: 0.0957 \n",
      "Epoch 12/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0901 - mse: 0.0887 \n",
      "Epoch 13/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0830 - mse: 0.0818 \n",
      "Epoch 14/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0769 - mse: 0.0758 \n",
      "Epoch 15/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0707 - mse: 0.0697 \n",
      "Epoch 16/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0658 - mse: 0.0650 \n",
      "Epoch 17/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0610 - mse: 0.0603 \n",
      "Epoch 18/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0565 - mse: 0.0559 \n",
      "Epoch 19/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0523 - mse: 0.0518 \n",
      "Epoch 20/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0490 - mse: 0.0486 \n",
      "Epoch 21/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0455 - mse: 0.0451 \n",
      "Epoch 22/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0427 - mse: 0.0423 \n",
      "Epoch 23/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0400 - mse: 0.0397 \n",
      "Epoch 24/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0374 - mse: 0.0371 \n",
      "Epoch 25/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0353 - mse: 0.0350 \n",
      "Epoch 26/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0336 - mse: 0.0333 \n",
      "Epoch 27/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0318 - mse: 0.0316 \n",
      "Epoch 28/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0303 - mse: 0.0300 \n",
      "Epoch 29/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0284 - mse: 0.0282 \n",
      "Epoch 30/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0276 - mse: 0.0274 \n",
      "Epoch 31/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0266 - mse: 0.0264 \n",
      "Epoch 32/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0252 - mse: 0.0250 \n",
      "Epoch 33/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0248 - mse: 0.0247 \n",
      "Epoch 34/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0238 - mse: 0.0237 \n",
      "Epoch 35/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0227 - mse: 0.0226 \n",
      "Epoch 36/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0221 - mse: 0.0219 \n",
      "Epoch 37/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0216 - mse: 0.0215 \n",
      "Epoch 38/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0207 - mse: 0.0206 \n",
      "Epoch 39/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0205 - mse: 0.0204 \n",
      "Epoch 40/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0194 - mse: 0.0193 \n",
      "Epoch 41/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0190 - mse: 0.0190 \n",
      "Epoch 42/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0187 - mse: 0.0187 \n",
      "Epoch 43/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - mse: 0.0187 \n",
      "Epoch 44/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mse: 0.0180 \n",
      "Epoch 45/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0180 - mse: 0.0179 \n",
      "Epoch 46/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0177 - mse: 0.0177 \n",
      "Epoch 47/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - mse: 0.0169 \n",
      "Epoch 48/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0169 - mse: 0.0169 \n",
      "Epoch 49/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0169 - mse: 0.0168 \n",
      "Epoch 50/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0169 - mse: 0.0168 \n",
      "Epoch 51/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0163 - mse: 0.0162 \n",
      "Epoch 52/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0161 - mse: 0.0161 \n",
      "Epoch 53/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0160 - mse: 0.0160 \n",
      "Epoch 54/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0161 - mse: 0.0161 \n",
      "Epoch 55/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0159 - mse: 0.0158 \n",
      "Epoch 56/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0154 - mse: 0.0154 \n",
      "Epoch 57/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0152 - mse: 0.0151 \n",
      "Epoch 58/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0153 - mse: 0.0153 \n",
      "Epoch 59/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0150 - mse: 0.0150 \n",
      "Epoch 60/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0146 - mse: 0.0146 \n",
      "Epoch 61/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0149 - mse: 0.0149 \n",
      "Epoch 62/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0146 - mse: 0.0146 \n",
      "Epoch 63/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0148 - mse: 0.0148 \n",
      "Epoch 64/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0151 - mse: 0.0150 \n",
      "Epoch 65/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0141 - mse: 0.0141 \n",
      "Epoch 66/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0146 - mse: 0.0146 \n",
      "Epoch 67/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0145 - mse: 0.0144 \n",
      "Epoch 68/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0141 - mse: 0.0141 \n",
      "Epoch 69/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0140 - mse: 0.0140 \n",
      "Epoch 70/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0142 - mse: 0.0142 \n",
      "Epoch 71/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0137 - mse: 0.0136 \n",
      "Epoch 72/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0138 - mse: 0.0138 \n",
      "Epoch 73/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - mse: 0.0137 \n",
      "Epoch 74/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0135 - mse: 0.0134 \n",
      "Epoch 75/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - mse: 0.0135 \n",
      "Epoch 76/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mse: 0.0140 \n",
      "Epoch 77/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0136 - mse: 0.0136 \n",
      "Epoch 78/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0131 - mse: 0.0131 \n",
      "Epoch 79/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - mse: 0.0135 \n",
      "Epoch 80/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0134 - mse: 0.0134 \n",
      "Epoch 81/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 82/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0132 - mse: 0.0132 \n",
      "Epoch 83/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - mse: 0.0132 \n",
      "Epoch 84/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0132 - mse: 0.0131 \n",
      "Epoch 85/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0136 - mse: 0.0136 \n",
      "Epoch 86/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0133 - mse: 0.0133 \n",
      "Epoch 87/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - mse: 0.0128 \n",
      "Epoch 88/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mse: 0.0129 \n",
      "Epoch 89/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0134 - mse: 0.0134 \n",
      "Epoch 90/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mse: 0.0131 \n",
      "Epoch 91/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 92/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0137 - mse: 0.0136 \n",
      "Epoch 93/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 94/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 95/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 96/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 97/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 98/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 99/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 100/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 101/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 102/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 103/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 104/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 105/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 106/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 107/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 108/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 109/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 110/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 111/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0133 - mse: 0.0133 \n",
      "Epoch 112/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 113/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0131 - mse: 0.0131 \n",
      "Epoch 114/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 115/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 116/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 117/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 118/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 119/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 120/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 121/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 122/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 123/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 124/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 125/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 126/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 127/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 128/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 129/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 130/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 131/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 132/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 133/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 134/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 135/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 136/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 137/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 138/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 139/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 140/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 141/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 142/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0115 - mse: 0.0115 \n",
      "Epoch 143/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 144/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0125 \n",
      "Epoch 145/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 146/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 147/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 148/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 149/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 150/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 151/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 152/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 153/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 154/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 155/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 156/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 157/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 158/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 159/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 160/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 161/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 162/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 163/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 164/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 165/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 166/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 167/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 168/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 169/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 170/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 171/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 172/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 173/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 174/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 175/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 176/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 177/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 178/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 179/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 180/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 181/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 182/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 183/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 184/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 185/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 186/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 187/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 188/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 189/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 190/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 191/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0116 - mse: 0.0116 \n",
      "Epoch 192/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0114 - mse: 0.0114 \n",
      "Epoch 193/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0116 - mse: 0.0116 \n",
      "Epoch 194/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 195/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 196/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 197/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 198/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 199/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 200/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n"
     ]
    }
   ],
   "source": [
    "history = ae.fit(train_data, 128, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label=\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7744969 , 0.70154715, 0.55967736, ..., 0.01821313, 0.02240672,\n",
       "        0.01793109],\n",
       "       [0.7744969 , 0.70154715, 0.55967736, ..., 0.01821313, 0.02240672,\n",
       "        0.01793109],\n",
       "       [0.77446234, 0.7015953 , 0.5596642 , ..., 0.01821915, 0.02242015,\n",
       "        0.01793751],\n",
       "       ...,\n",
       "       [0.77497095, 0.70223504, 0.5600356 , ..., 0.01802483, 0.02220454,\n",
       "        0.01774113],\n",
       "       [0.7744969 , 0.70154715, 0.55967736, ..., 0.01821313, 0.02240672,\n",
       "        0.01793109],\n",
       "       [0.7748136 , 0.7014252 , 0.5596877 , ..., 0.0181079 , 0.02226654,\n",
       "        0.0178339 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.model.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ preprocessing_layer │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PreprocessingLaye…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">936</span> │ preprocessing_la… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">162</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">969</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convert_to_tensor_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ preprocessing_la… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvertToTensor</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convert_to_tensor   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvertToTensor</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ convert_to_tenso… │\n",
       "│                     │                   │            │ convert_to_tenso… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ square (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Square</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ subtract[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Mean</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ square[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ preprocessing_layer │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mPreprocessingLaye…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │        \u001b[38;5;34m936\u001b[0m │ preprocessing_la… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m152\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │        \u001b[38;5;34m162\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │        \u001b[38;5;34m969\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convert_to_tensor_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ preprocessing_la… │\n",
       "│ (\u001b[38;5;33mConvertToTensor\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convert_to_tensor   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mConvertToTensor\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract (\u001b[38;5;33mSubtract\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ convert_to_tenso… │\n",
       "│                     │                   │            │ convert_to_tenso… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ square (\u001b[38;5;33mSquare\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ subtract[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (\u001b[38;5;33mMean\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ square[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,219</span> (8.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,219\u001b[0m (8.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,219</span> (8.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,219\u001b[0m (8.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.02622933, 0.03181145, 0.04320111, 0.05795019, 0.0103389 ,\n",
       "       0.05049328, 0.00876535, 0.00988122, 0.02610688, 0.06245252,\n",
       "       0.03201437, 0.01195818, 0.04108442, 0.01075046, 0.03926809,\n",
       "       0.03666726, 0.05400687, 0.05772702, 0.00734805, 0.03454347,\n",
       "       0.02107488, 0.02230364, 0.02091778, 0.00896701, 0.00975878,\n",
       "       0.01968648, 0.01765603, 0.00906225, 0.0265705 , 0.01227898,\n",
       "       0.00736647, 0.00477947, 0.0288176 , 0.01226225, 0.0222666 ,\n",
       "       0.00643161, 0.05572913, 0.01779468, 0.01882103, 0.00599936,\n",
       "       0.03158294, 0.02106088, 0.03599528, 0.01012171, 0.01107514,\n",
       "       0.03621636, 0.03281334, 0.01870886, 0.01921682, 0.04807718,\n",
       "       0.0094018 , 0.02964693, 0.03919168, 0.03769621, 0.03097173,\n",
       "       0.05397988, 0.01293536, 0.02519506, 0.03039234, 0.01086318,\n",
       "       0.01807727, 0.04630703, 0.00965777, 0.03214826, 0.00860205,\n",
       "       0.03091669, 0.00601985, 0.01841327, 0.01276514, 0.0152799 ,\n",
       "       0.02575261, 0.01182579, 0.03925202, 0.06160836, 0.03967522,\n",
       "       0.02460528, 0.0354222 , 0.06233098, 0.0238168 , 0.05508766,\n",
       "       0.04443508, 0.01170949, 0.01297951, 0.02322335, 0.06045101,\n",
       "       0.01320838, 0.03709001, 0.01687296, 0.05029491, 0.06350707,\n",
       "       0.01708835, 0.02425986, 0.05432395, 0.02228282, 0.00897129,\n",
       "       0.01003511, 0.02393035, 0.02588728, 0.02760271, 0.042918  ,\n",
       "       0.03694244, 0.03841101, 0.01483703, 0.01731945, 0.02433371,\n",
       "       0.02455666, 0.03510074, 0.04503327, 0.03274051, 0.04120357,\n",
       "       0.014726  , 0.01655553, 0.02039459, 0.01874804, 0.033975  ,\n",
       "       0.05396647, 0.04589048, 0.02132659, 0.03083162, 0.05450504,\n",
       "       0.054749  , 0.04626856, 0.05641807, 0.03921525, 0.00749451,\n",
       "       0.04958879, 0.03473965, 0.1452532 , 0.01949156, 0.02934957,\n",
       "       0.0412842 , 0.04413265, 0.01785236, 0.04846719, 0.01407231,\n",
       "       0.00798178, 0.04406236, 0.00897118, 0.03585057, 0.01843331,\n",
       "       0.00832362, 0.04702649, 0.0145563 , 0.0077346 , 0.01158798,\n",
       "       0.00972316, 0.05741307, 0.0330771 , 0.02403836, 0.02038012,\n",
       "       0.01186767, 0.00735976, 0.04375194, 0.04063915, 0.02357859,\n",
       "       0.01780618, 0.03390516, 0.06489107, 0.03419187, 0.03690456,\n",
       "       0.06991343, 0.01202686, 0.04914829, 0.03937433, 0.03010857,\n",
       "       0.01038191, 0.04862933, 0.0254645 , 0.05855786, 0.01247524,\n",
       "       0.00909106, 0.04792072, 0.01437754, 0.02868157, 0.04815525,\n",
       "       0.03246199, 0.05319626, 0.04299201, 0.02478592, 0.04313726,\n",
       "       0.02092596, 0.04385305, 0.05134757, 0.01604789, 0.03330283,\n",
       "       0.023489  , 0.02709146, 0.01723093, 0.05732985, 0.01072454,\n",
       "       0.05229578, 0.02802241, 0.01641114, 0.0345241 , 0.07261607,\n",
       "       0.02056673, 0.03302304, 0.01640289, 0.03250301, 0.03714694,\n",
       "       0.0455023 , 0.01565637, 0.03791516, 0.03806038, 0.01951033,\n",
       "       0.02331468, 0.03913842, 0.01657425, 0.01797102, 0.01191513,\n",
       "       0.03936472, 0.01493373, 0.06324343, 0.05136146, 0.05160633,\n",
       "       0.04445295, 0.01177415, 0.020257  , 0.01375939, 0.01015677,\n",
       "       0.01995578, 0.01219923, 0.03874696, 0.01200031, 0.06175688,\n",
       "       0.0291727 , 0.02125847, 0.03499936, 0.01833802, 0.03543084,\n",
       "       0.04678701, 0.0114316 , 0.03404155, 0.04721507, 0.07088419,\n",
       "       0.02207832, 0.00676355, 0.04746782, 0.00417458, 0.0669757 ,\n",
       "       0.04976146, 0.01310712, 0.02364171, 0.00990851, 0.03204311,\n",
       "       0.04866774, 0.03252707, 0.02761447, 0.02704256, 0.03298781,\n",
       "       0.04055475, 0.01684975, 0.00990884, 0.01514855, 0.05118794,\n",
       "       0.01477689, 0.0344444 , 0.03272242, 0.00980583, 0.01247653,\n",
       "       0.02759751, 0.02359308, 0.03801022, 0.03455412, 0.02336889,\n",
       "       0.01738574, 0.00897094, 0.02752295, 0.01566667, 0.02418025,\n",
       "       0.01774698, 0.03018362, 0.01926306, 0.01168242, 0.03656471,\n",
       "       0.01765495, 0.04074187, 0.03735358, 0.01447479, 0.02293709,\n",
       "       0.03441233, 0.03626685, 0.01599346, 0.01151094, 0.03848987,\n",
       "       0.01037548, 0.05463027, 0.01419536, 0.00635246, 0.04616306,\n",
       "       0.04652048, 0.04673593, 0.01514646, 0.02747808, 0.03108983,\n",
       "       0.0324081 , 0.05231107, 0.02962173, 0.05156185, 0.00831982,\n",
       "       0.04073156, 0.02888942, 0.006046  , 0.03095411, 0.06152507,\n",
       "       0.05773225, 0.04028279, 0.00490673, 0.04484899, 0.00682602,\n",
       "       0.03611156, 0.02578245, 0.01161274, 0.0231731 , 0.01157761,\n",
       "       0.02414565, 0.01305599, 0.00975114, 0.01656973, 0.05730801,\n",
       "       0.03639542, 0.02025918, 0.03499836, 0.0284608 , 0.04839164,\n",
       "       0.03260061, 0.03143   , 0.03051155, 0.04796252, 0.01624484,\n",
       "       0.02622909, 0.04943723, 0.02367488, 0.01212153, 0.03632217,\n",
       "       0.04587678, 0.01780095, 0.02241669, 0.04201791, 0.05069454,\n",
       "       0.03202464, 0.02833257, 0.02114085, 0.05096474, 0.01757067,\n",
       "       0.03210773, 0.01951733, 0.03118011, 0.04155475, 0.01518036,\n",
       "       0.06785263, 0.05543702, 0.01442311, 0.05268113, 0.03237882,\n",
       "       0.04743814, 0.02794169, 0.02962673, 0.02514118, 0.01572071,\n",
       "       0.01094216, 0.01090777, 0.01482358, 0.00910286, 0.02617348,\n",
       "       0.07345243, 0.03150843, 0.03072037, 0.01417374, 0.04402418,\n",
       "       0.01454028, 0.02114695, 0.02842116, 0.0099801 , 0.05117081,\n",
       "       0.01384056, 0.03645692, 0.00770705, 0.0053042 , 0.00878216,\n",
       "       0.04940802, 0.03575224, 0.03668335, 0.02284729, 0.03628316,\n",
       "       0.02611542, 0.0294086 , 0.04882316, 0.04593097, 0.04885963,\n",
       "       0.04649515, 0.02442309, 0.00747369, 0.01955495, 0.01944439,\n",
       "       0.0321389 , 0.0139594 , 0.00802537, 0.02251244, 0.02184943,\n",
       "       0.03771773, 0.00964639, 0.0202594 , 0.01205924, 0.02959465,\n",
       "       0.01046849, 0.01329951, 0.00683704, 0.02592808, 0.03283126,\n",
       "       0.00633915, 0.02862729, 0.02522111, 0.02875501, 0.01460102,\n",
       "       0.07933541, 0.01296278, 0.01401353, 0.05764017, 0.031067  ,\n",
       "       0.01247877, 0.03921728, 0.00648698, 0.03309012, 0.01175066,\n",
       "       0.02709551, 0.03421362, 0.0109956 , 0.00855665, 0.02143831,\n",
       "       0.00797292, 0.04448624, 0.02145996, 0.01412471, 0.01253073,\n",
       "       0.00934322, 0.02816138, 0.03633963, 0.03283545, 0.03112013,\n",
       "       0.02230348, 0.02872068, 0.01340009, 0.04348629, 0.03990656,\n",
       "       0.02909276, 0.04352889, 0.01998506, 0.0579322 , 0.02417528,\n",
       "       0.05256149, 0.02906115, 0.02564848, 0.04566987, 0.02870053,\n",
       "       0.02940711, 0.05689383, 0.01957719, 0.02505838, 0.01561116,\n",
       "       0.02068699, 0.01650776, 0.01429504, 0.03811826, 0.0390867 ,\n",
       "       0.01773828, 0.04933033, 0.01269497, 0.0125356 , 0.00548752,\n",
       "       0.0359215 , 0.05569721, 0.03510451, 0.00883421, 0.03550335,\n",
       "       0.01215913, 0.01439952, 0.04152026, 0.01707896, 0.02055142,\n",
       "       0.05059318, 0.03827357, 0.02021359, 0.02947837, 0.01967222,\n",
       "       0.03293088, 0.01887731, 0.04434655, 0.00930476, 0.03980335,\n",
       "       0.00516123, 0.04607265, 0.03315703, 0.01477561, 0.01166207,\n",
       "       0.02947823, 0.01759838, 0.02011785, 0.04443104, 0.01756293,\n",
       "       0.01400592, 0.05532748, 0.04192954, 0.01788189, 0.01216237,\n",
       "       0.01695659, 0.02083003, 0.03091652, 0.00845634, 0.04286365,\n",
       "       0.00907586, 0.02782076, 0.03034872, 0.05608758, 0.03477523,\n",
       "       0.03240757, 0.04613778, 0.07896049, 0.01086553, 0.02459631,\n",
       "       0.03214747, 0.00746788, 0.01677803, 0.05184003, 0.01169477,\n",
       "       0.03062586, 0.03160079, 0.01442309, 0.02659534, 0.03941938,\n",
       "       0.0541084 , 0.02702443, 0.04944645, 0.02053931, 0.0426953 ,\n",
       "       0.01782215, 0.02093419, 0.00461278, 0.03675814, 0.01208299,\n",
       "       0.00907707, 0.06025866, 0.04138688, 0.0047917 , 0.05006968,\n",
       "       0.02623199, 0.03134421, 0.00988139, 0.01423992, 0.0165019 ,\n",
       "       0.02679574, 0.03007006, 0.01922856, 0.01914639, 0.02192464,\n",
       "       0.01466691, 0.04381086, 0.03171646, 0.00655389, 0.02683728,\n",
       "       0.01533346, 0.00840714, 0.04616105, 0.04406556, 0.0176129 ,\n",
       "       0.01963721, 0.02376745, 0.03867418, 0.03517926, 0.02844024,\n",
       "       0.04834466, 0.046698  , 0.03283156, 0.02605981, 0.0394349 ,\n",
       "       0.02385529, 0.02664874, 0.01880957, 0.01664731, 0.01047191,\n",
       "       0.0323249 , 0.01006932, 0.01911172, 0.01973929, 0.04682719,\n",
       "       0.02660431, 0.00736127, 0.01088901, 0.02497651, 0.0157787 ,\n",
       "       0.02357255, 0.02938981, 0.03987045, 0.01346615, 0.02648543,\n",
       "       0.06855934, 0.01669093, 0.0231337 , 0.01419052, 0.0465597 ,\n",
       "       0.0138715 , 0.03532534, 0.0291361 , 0.03838426, 0.01833471,\n",
       "       0.01343419, 0.02106153, 0.01184842, 0.04073619, 0.01025568,\n",
       "       0.01304817, 0.0256949 , 0.02810712, 0.01281198, 0.02586647,\n",
       "       0.01057601, 0.01143932, 0.02725939, 0.02034387, 0.01214927,\n",
       "       0.01591015, 0.01565644, 0.04238385, 0.00752407, 0.00738182,\n",
       "       0.01163098, 0.04059138, 0.00871882, 0.01870449, 0.03439778,\n",
       "       0.03154187, 0.00777815, 0.02659945, 0.05331333, 0.01031268,\n",
       "       0.01557464, 0.00571582, 0.02207763, 0.06024956, 0.10645488,\n",
       "       0.07592471, 0.08162824, 0.05704276, 0.07358282, 0.06346764,\n",
       "       0.07786128, 0.06932916, 0.04102832, 0.04519308, 0.04152859,\n",
       "       0.07267783, 0.07122514, 0.0889876 , 0.05448011, 0.04858965,\n",
       "       0.06367163, 0.04143135, 0.01391253, 0.02055436, 0.01916393,\n",
       "       0.02995539, 0.02951292, 0.01545569, 0.03173354, 0.00924122,\n",
       "       0.01821494, 0.02698862, 0.01557691, 0.05620481, 0.02354741,\n",
       "       0.00679114, 0.03321715, 0.01233785, 0.01124189, 0.04677472,\n",
       "       0.06444504, 0.08619291, 0.0145107 , 0.0240456 , 0.00836951,\n",
       "       0.03572221, 0.04894415, 0.04808259, 0.05769696, 0.00476689,\n",
       "       0.02834586, 0.01581508, 0.09986442, 0.03975838, 0.02547688,\n",
       "       0.02550793, 0.05142279, 0.03401608, 0.01681373, 0.02839692,\n",
       "       0.01490127, 0.0489752 , 0.04696931, 0.02562679, 0.0408811 ,\n",
       "       0.0091156 , 0.0471439 , 0.0429406 , 0.03107869, 0.01351492,\n",
       "       0.01180143, 0.02899379, 0.01273124, 0.03970416, 0.02189828,\n",
       "       0.04857154, 0.03387313, 0.08350733, 0.05392234, 0.05733036],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.stripped_model.summary()\n",
    "ae.stripped_model.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/tensorflow/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/tensorflow/1/assets\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../models/tensorflow\", exist_ok=True)\n",
    "\n",
    "model_path = \"../models/tensorflow/1/\"\n",
    "tf.saved_model.save(ae.stripped_model, model_path)\n",
    "\n",
    "# We could save the full model, by referencing ae.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-examples-EfRPkUGI-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
