{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 16:52:30.629770: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-05 16:52:30.639593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741189950.651842   72014 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741189950.655597   72014 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-05 16:52:30.668053: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PreprocessingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        min_val = tf.reduce_min(inputs, axis=0)\n",
    "        max_val = tf.reduce_max(inputs, axis=0)\n",
    "        normalized_inputs = tf.where(\n",
    "            max_val - min_val != 0,\n",
    "            (inputs - min_val) / (max_val - min_val + 1e-8),\n",
    "            tf.zeros_like(inputs),\n",
    "        )\n",
    "        return normalized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder:\n",
    "    \"\"\"Autoencoder that reconstruct METSig distributions and flag anomalies\"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: tuple[int], l2_lambda: float):\n",
    "        input_layer = tf.keras.Input(shape=input_shape)\n",
    "        prep_layer = PreprocessingLayer()(input_layer)\n",
    "        encoded = tf.keras.layers.Dense(18, activation=\"relu\", activity_regularizer=tf.keras.regularizers.l2(l2_lambda))(prep_layer)\n",
    "        encoded = tf.keras.layers.Dense(8, activation=\"sigmoid\")(encoded)\n",
    "        decoded = tf.keras.layers.Dense(18, activation=\"sigmoid\")(encoded)\n",
    "        decoded = tf.keras.layers.Dense(input_shape[0], activation=\"sigmoid\")(decoded)\n",
    "        self.model = tf.keras.models.Model(input_layer, decoded)\n",
    "\n",
    "        # Since `avg_mse` shares the same layers (prep_layer and decoded) as the `self.model`\n",
    "        # this `self.stripped_model` doesn't need to be trained\n",
    "        avg_mse = tf.keras.losses.MSE(prep_layer, decoded)  # Compute the mean squared error for each row in the inputs\n",
    "        self.stripped_model = tf.keras.models.Model(input_layer, avg_mse)\n",
    "\n",
    "    def compile(self):\n",
    "        self.model.compile(optimizer=\"adam\", loss=[\"mse\"], metrics=[\"mse\"])\n",
    "\n",
    "    def summary(self):\n",
    "        self.model.summary()\n",
    "\n",
    "    def predict(self, inputs: np.ndarray):\n",
    "        return self.model.predict(inputs)\n",
    "\n",
    "    def fit(self, inputs: np.ndarray, batch_size: int, epochs: int):\n",
    "        targets = PreprocessingLayer()(inputs)\n",
    "        history: tf.keras.callbacks.History = self.model.fit(\n",
    "            inputs, targets, batch_size=batch_size, epochs=epochs\n",
    "        )\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1940., 1987.,  670., ...,    0.,    0.,    0.],\n",
       "       [1869., 1872.,  714., ...,    0.,    0.,    0.],\n",
       "       [1819., 1924.,  672., ...,    0.,    0.,    0.],\n",
       "       ...,\n",
       "       [1171.,  989.,  293., ...,    0.,    0.,    0.],\n",
       "       [1225.,  960.,  289., ...,    0.,    0.,    0.],\n",
       "       [1190.,  994.,  257., ...,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.load(\"data/data_386642.npy\")\n",
    "train_label = np.load(\"data/label_386642.npy\")\n",
    "\n",
    "# We want to feed the Autoencoder with GOOD data, so we filter the data by the label == 1\n",
    "train_data = train_data[train_label == 1]\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-05 16:52:34.653902: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ preprocessing_layer             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PreprocessingLayer</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">936</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">162</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">969</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ preprocessing_layer             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mPreprocessingLayer\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m936\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m162\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)             │           \u001b[38;5;34m969\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,219</span> (8.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,219\u001b[0m (8.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,219</span> (8.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,219\u001b[0m (8.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ae = Autoencoder(input_shape=(51,), l2_lambda=1e-4)\n",
    "ae.compile()\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2280 - mse: 0.2214  \n",
      "Epoch 2/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.2141 - mse: 0.2090 \n",
      "Epoch 3/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2008 - mse: 0.1967 \n",
      "Epoch 4/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1885 - mse: 0.1853 \n",
      "Epoch 5/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1770 - mse: 0.1744 \n",
      "Epoch 6/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1660 - mse: 0.1640 \n",
      "Epoch 7/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1554 - mse: 0.1538 \n",
      "Epoch 8/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1450 - mse: 0.1438 \n",
      "Epoch 9/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1353 - mse: 0.1343 \n",
      "Epoch 10/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1262 - mse: 0.1254 \n",
      "Epoch 11/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1172 - mse: 0.1165 \n",
      "Epoch 12/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1089 - mse: 0.1083 \n",
      "Epoch 13/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.1010 - mse: 0.1005 \n",
      "Epoch 14/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0933 - mse: 0.0929 \n",
      "Epoch 15/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0863 - mse: 0.0860 \n",
      "Epoch 16/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0800 - mse: 0.0797 \n",
      "Epoch 17/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0738 - mse: 0.0736 \n",
      "Epoch 18/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0684 - mse: 0.0681 \n",
      "Epoch 19/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0633 - mse: 0.0631 \n",
      "Epoch 20/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0585 - mse: 0.0583 \n",
      "Epoch 21/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0546 - mse: 0.0545 \n",
      "Epoch 22/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0510 - mse: 0.0508 \n",
      "Epoch 23/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0471 - mse: 0.0469 \n",
      "Epoch 24/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0443 - mse: 0.0442 \n",
      "Epoch 25/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0411 - mse: 0.0410 \n",
      "Epoch 26/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0392 - mse: 0.0391 \n",
      "Epoch 27/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - mse: 0.0365 \n",
      "Epoch 28/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0346 - mse: 0.0345 \n",
      "Epoch 29/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0326 - mse: 0.0326 \n",
      "Epoch 30/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0307 - mse: 0.0307 \n",
      "Epoch 31/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0292 - mse: 0.0291 \n",
      "Epoch 32/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0282 - mse: 0.0281 \n",
      "Epoch 33/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0275 - mse: 0.0274 \n",
      "Epoch 34/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0259 - mse: 0.0258 \n",
      "Epoch 35/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - mse: 0.0251 \n",
      "Epoch 36/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0240 - mse: 0.0240 \n",
      "Epoch 37/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - mse: 0.0230 \n",
      "Epoch 38/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227 - mse: 0.0226 \n",
      "Epoch 39/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0221 - mse: 0.0220 \n",
      "Epoch 40/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0212 - mse: 0.0211 \n",
      "Epoch 41/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0204 - mse: 0.0204 \n",
      "Epoch 42/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - mse: 0.0201 \n",
      "Epoch 43/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - mse: 0.0195 \n",
      "Epoch 44/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - mse: 0.0190 \n",
      "Epoch 45/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0190 - mse: 0.0189 \n",
      "Epoch 46/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - mse: 0.0184 \n",
      "Epoch 47/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - mse: 0.0184 \n",
      "Epoch 48/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - mse: 0.0183 \n",
      "Epoch 49/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0175 - mse: 0.0175 \n",
      "Epoch 50/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0169 - mse: 0.0169 \n",
      "Epoch 51/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0166 - mse: 0.0166 \n",
      "Epoch 52/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0164 - mse: 0.0164 \n",
      "Epoch 53/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0165 - mse: 0.0165 \n",
      "Epoch 54/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0163 - mse: 0.0163 \n",
      "Epoch 55/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0163 - mse: 0.0163 \n",
      "Epoch 56/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0159 - mse: 0.0159 \n",
      "Epoch 57/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0158 - mse: 0.0158 \n",
      "Epoch 58/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0157 - mse: 0.0157 \n",
      "Epoch 59/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0154 - mse: 0.0154 \n",
      "Epoch 60/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0155 - mse: 0.0154 \n",
      "Epoch 61/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0148 - mse: 0.0148 \n",
      "Epoch 62/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0149 - mse: 0.0149 \n",
      "Epoch 63/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0145 - mse: 0.0145\n",
      "Epoch 64/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0148 - mse: 0.0148 \n",
      "Epoch 65/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0148 - mse: 0.0148 \n",
      "Epoch 66/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0146 - mse: 0.0146 \n",
      "Epoch 67/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0147 - mse: 0.0147 \n",
      "Epoch 68/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0144 - mse: 0.0144 \n",
      "Epoch 69/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0140 - mse: 0.0140 \n",
      "Epoch 70/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0139 - mse: 0.0139 \n",
      "Epoch 71/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0142 - mse: 0.0142 \n",
      "Epoch 72/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mse: 0.0140 \n",
      "Epoch 73/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0139 - mse: 0.0139 \n",
      "Epoch 74/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0136 - mse: 0.0136 \n",
      "Epoch 75/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0136 - mse: 0.0136 \n",
      "Epoch 76/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0140 - mse: 0.0139 \n",
      "Epoch 77/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0140 - mse: 0.0139 \n",
      "Epoch 78/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0138 - mse: 0.0138 \n",
      "Epoch 79/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0137 - mse: 0.0137 \n",
      "Epoch 80/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0139 - mse: 0.0139 \n",
      "Epoch 81/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0136 - mse: 0.0136 \n",
      "Epoch 82/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0135 - mse: 0.0135 \n",
      "Epoch 83/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0140 - mse: 0.0140 \n",
      "Epoch 84/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0135 - mse: 0.0135 \n",
      "Epoch 85/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 86/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0133 - mse: 0.0133 \n",
      "Epoch 87/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0133 - mse: 0.0133 \n",
      "Epoch 88/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0134 - mse: 0.0134 \n",
      "Epoch 89/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 90/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0138 - mse: 0.0138 \n",
      "Epoch 91/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0131 - mse: 0.0131 \n",
      "Epoch 92/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0132 - mse: 0.0132 \n",
      "Epoch 93/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 94/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 95/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 96/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 97/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 98/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 99/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0133 - mse: 0.0133 \n",
      "Epoch 100/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 101/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - mse: 0.0132 \n",
      "Epoch 102/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 103/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 104/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 105/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 106/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 107/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - mse: 0.0128 \n",
      "Epoch 108/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 109/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 110/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 111/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0129 - mse: 0.0129 \n",
      "Epoch 112/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 113/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 114/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 115/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0130 - mse: 0.0130 \n",
      "Epoch 116/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 117/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 118/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0129 - mse: 0.0128 \n",
      "Epoch 119/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - mse: 0.0128 \n",
      "Epoch 120/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0132 - mse: 0.0132 \n",
      "Epoch 121/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 122/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 123/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 124/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0128 - mse: 0.0128 \n",
      "Epoch 125/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 126/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 127/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 128/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 129/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 130/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 131/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 132/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 133/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 134/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 135/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 136/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 137/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 138/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 139/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 140/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 141/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 142/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 143/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 144/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 145/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 146/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 147/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0127 - mse: 0.0127 \n",
      "Epoch 148/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 149/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 150/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0126 - mse: 0.0126 \n",
      "Epoch 151/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 152/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 153/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 154/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 155/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 156/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 157/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 158/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 159/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 160/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 161/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 162/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 163/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 164/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0121 - mse: 0.0121\n",
      "Epoch 165/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 166/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 167/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 168/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 169/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0125 - mse: 0.0125 \n",
      "Epoch 170/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 171/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0119 - mse: 0.0119 \n",
      "Epoch 172/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 173/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 174/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 175/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 176/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0124 - mse: 0.0124 \n",
      "Epoch 177/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 178/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 179/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 180/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0117 - mse: 0.0117 \n",
      "Epoch 181/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 182/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 183/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 184/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 185/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 186/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 187/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 188/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0118 - mse: 0.0118 \n",
      "Epoch 189/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0123 - mse: 0.0123 \n",
      "Epoch 190/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0120 - mse: 0.0120\n",
      "Epoch 191/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 192/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 193/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 194/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 195/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0115 - mse: 0.0115 \n",
      "Epoch 196/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0120 - mse: 0.0120 \n",
      "Epoch 197/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0121 - mse: 0.0121 \n",
      "Epoch 198/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0115 - mse: 0.0115 \n",
      "Epoch 199/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0122 - mse: 0.0122 \n",
      "Epoch 200/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0119 - mse: 0.0119 \n"
     ]
    }
   ],
   "source": [
    "history = ae.fit(train_data, 128, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label=\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.77278346, 0.6978961 , 0.55414665, ..., 0.01567058, 0.0255139 ,\n",
       "        0.0152659 ],\n",
       "       [0.77278346, 0.6978961 , 0.55414665, ..., 0.01567058, 0.0255139 ,\n",
       "        0.0152659 ],\n",
       "       [0.7728268 , 0.69799846, 0.5541415 , ..., 0.01564432, 0.02548023,\n",
       "        0.01523753],\n",
       "       ...,\n",
       "       [0.7727282 , 0.6978194 , 0.5540776 , ..., 0.0156825 , 0.02553566,\n",
       "        0.0152702 ],\n",
       "       [0.77278346, 0.6978961 , 0.55414665, ..., 0.01567058, 0.0255139 ,\n",
       "        0.0152659 ],\n",
       "       [0.77278346, 0.6978961 , 0.55414665, ..., 0.01567058, 0.0255139 ,\n",
       "        0.0152659 ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.model.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ preprocessing_layer │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PreprocessingLaye…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">936</span> │ preprocessing_la… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">162</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">969</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convert_to_tensor_1 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ preprocessing_la… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvertToTensor</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convert_to_tensor   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvertToTensor</span>)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Subtract</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ convert_to_tenso… │\n",
       "│                     │                   │            │ convert_to_tenso… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ square (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Square</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ subtract[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Mean</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ square[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ preprocessing_layer │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mPreprocessingLaye…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │        \u001b[38;5;34m936\u001b[0m │ preprocessing_la… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m152\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │        \u001b[38;5;34m162\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │        \u001b[38;5;34m969\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convert_to_tensor_1 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ preprocessing_la… │\n",
       "│ (\u001b[38;5;33mConvertToTensor\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ convert_to_tensor   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mConvertToTensor\u001b[0m)   │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ subtract (\u001b[38;5;33mSubtract\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ convert_to_tenso… │\n",
       "│                     │                   │            │ convert_to_tenso… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ square (\u001b[38;5;33mSquare\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ subtract[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ mean (\u001b[38;5;33mMean\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m)            │          \u001b[38;5;34m0\u001b[0m │ square[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,219</span> (8.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,219\u001b[0m (8.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,219</span> (8.67 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,219\u001b[0m (8.67 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.02625392, 0.03192382, 0.04359365, 0.05790412, 0.01040803,\n",
       "       0.05053362, 0.00876837, 0.01004119, 0.02619381, 0.06219037,\n",
       "       0.03198015, 0.01206163, 0.04114974, 0.01079934, 0.03893512,\n",
       "       0.03657918, 0.05422409, 0.05799835, 0.00743811, 0.03463427,\n",
       "       0.02114946, 0.02237306, 0.02102852, 0.0090321 , 0.00988746,\n",
       "       0.01974664, 0.01772877, 0.00917191, 0.02670236, 0.01233403,\n",
       "       0.00743975, 0.00486084, 0.02873793, 0.01229925, 0.02259806,\n",
       "       0.00646564, 0.05586413, 0.01781443, 0.01879432, 0.00599061,\n",
       "       0.03141207, 0.02107469, 0.03602971, 0.01009607, 0.01114225,\n",
       "       0.03590659, 0.03299109, 0.01868774, 0.01924613, 0.04847216,\n",
       "       0.00949249, 0.02972272, 0.03880122, 0.03772842, 0.03106262,\n",
       "       0.05424831, 0.01290518, 0.0252893 , 0.03016987, 0.01081999,\n",
       "       0.01806089, 0.0462181 , 0.00961499, 0.03178373, 0.00879776,\n",
       "       0.03098842, 0.0061973 , 0.0184636 , 0.0129111 , 0.01540525,\n",
       "       0.02584731, 0.01199601, 0.03937629, 0.06145121, 0.03968176,\n",
       "       0.02476663, 0.03561488, 0.06247792, 0.02389227, 0.05529004,\n",
       "       0.04485354, 0.01178834, 0.01309177, 0.02338676, 0.06100471,\n",
       "       0.01341639, 0.03748421, 0.01706926, 0.05055817, 0.06339808,\n",
       "       0.01707093, 0.02431733, 0.05450393, 0.02241242, 0.00901036,\n",
       "       0.01010775, 0.02381858, 0.02590595, 0.02761928, 0.0430169 ,\n",
       "       0.03701057, 0.03841144, 0.01472683, 0.01733731, 0.02431767,\n",
       "       0.02454701, 0.03499179, 0.04497635, 0.03263817, 0.04113496,\n",
       "       0.01474323, 0.01665382, 0.02032907, 0.01861707, 0.03397283,\n",
       "       0.05400939, 0.04575011, 0.02113084, 0.03072645, 0.05420038,\n",
       "       0.05498841, 0.04621397, 0.05621429, 0.03911478, 0.00761419,\n",
       "       0.04945204, 0.03442154, 0.14504302, 0.01952158, 0.02956816,\n",
       "       0.04136154, 0.04426759, 0.01793544, 0.04836318, 0.01413022,\n",
       "       0.00807396, 0.0442042 , 0.00912268, 0.03624069, 0.01856567,\n",
       "       0.00848706, 0.04724783, 0.01472205, 0.00784364, 0.01163533,\n",
       "       0.00995267, 0.05763089, 0.03320565, 0.02405253, 0.02041328,\n",
       "       0.0119346 , 0.00753418, 0.04377826, 0.04067788, 0.02352013,\n",
       "       0.01777998, 0.03389338, 0.06448233, 0.03419811, 0.03691057,\n",
       "       0.06952899, 0.01192618, 0.04902419, 0.03932089, 0.02994505,\n",
       "       0.01034487, 0.04861758, 0.02542117, 0.05833056, 0.01252034,\n",
       "       0.00916783, 0.04800393, 0.01444425, 0.02859284, 0.04805204,\n",
       "       0.03224133, 0.05287101, 0.04277814, 0.02456191, 0.04314278,\n",
       "       0.021096  , 0.04349173, 0.0515577 , 0.01600791, 0.0332745 ,\n",
       "       0.0233111 , 0.02709439, 0.01704289, 0.05713405, 0.01072065,\n",
       "       0.05197862, 0.02795451, 0.01656057, 0.03458233, 0.07261222,\n",
       "       0.02059225, 0.03317464, 0.01652464, 0.03256173, 0.0372904 ,\n",
       "       0.0457801 , 0.01579591, 0.03797924, 0.03841448, 0.01969274,\n",
       "       0.02334033, 0.03947797, 0.01672644, 0.0181301 , 0.01208887,\n",
       "       0.03962056, 0.01511993, 0.06349643, 0.05105061, 0.05184002,\n",
       "       0.04448544, 0.01194747, 0.02035506, 0.01372219, 0.0102544 ,\n",
       "       0.01994124, 0.01236888, 0.03895938, 0.01215358, 0.06146419,\n",
       "       0.02922576, 0.02123218, 0.0350602 , 0.01833399, 0.03521885,\n",
       "       0.04706717, 0.01156186, 0.03409266, 0.04691012, 0.07121119,\n",
       "       0.0221338 , 0.00691947, 0.04745596, 0.00423444, 0.06684418,\n",
       "       0.0498208 , 0.01311638, 0.02376278, 0.01009483, 0.03212211,\n",
       "       0.04878044, 0.03253304, 0.027775  , 0.02706323, 0.03306072,\n",
       "       0.04073671, 0.01686017, 0.00997315, 0.01519364, 0.05111258,\n",
       "       0.01477243, 0.03429052, 0.03241742, 0.00968473, 0.0123737 ,\n",
       "       0.02756244, 0.02328553, 0.03776715, 0.03481353, 0.02335202,\n",
       "       0.01726881, 0.00888911, 0.02745745, 0.01570284, 0.02402079,\n",
       "       0.01774254, 0.03009458, 0.0192102 , 0.01168797, 0.03637905,\n",
       "       0.0174938 , 0.04088766, 0.03712001, 0.01435024, 0.02275875,\n",
       "       0.03420162, 0.0360762 , 0.01587058, 0.01135702, 0.03839082,\n",
       "       0.01033187, 0.05446875, 0.0141403 , 0.00643364, 0.04609099,\n",
       "       0.04648131, 0.04681434, 0.01513638, 0.02750013, 0.03109708,\n",
       "       0.03238476, 0.05220505, 0.02952966, 0.05162477, 0.00844184,\n",
       "       0.04061737, 0.02884251, 0.00605207, 0.03116035, 0.06103685,\n",
       "       0.05766826, 0.04004993, 0.00498132, 0.04472968, 0.00689492,\n",
       "       0.03621141, 0.02568418, 0.01162039, 0.02313093, 0.01148676,\n",
       "       0.0241699 , 0.01297429, 0.00972341, 0.01652086, 0.05714751,\n",
       "       0.03608783, 0.02004704, 0.03481992, 0.02844114, 0.04848744,\n",
       "       0.03257754, 0.0312799 , 0.03034932, 0.04780136, 0.0160627 ,\n",
       "       0.02607819, 0.04934639, 0.02348284, 0.01211919, 0.03613936,\n",
       "       0.04556223, 0.0175698 , 0.02220695, 0.04179882, 0.05013092,\n",
       "       0.03211641, 0.02832805, 0.02094246, 0.05069591, 0.01736505,\n",
       "       0.03201591, 0.01949994, 0.03095824, 0.04135111, 0.01508686,\n",
       "       0.06790026, 0.05514781, 0.01458484, 0.05274877, 0.0325813 ,\n",
       "       0.04764235, 0.02821833, 0.02978847, 0.02534959, 0.0158521 ,\n",
       "       0.01112518, 0.01112477, 0.01491724, 0.00932028, 0.02630051,\n",
       "       0.07340655, 0.0316846 , 0.03079481, 0.01434646, 0.04390997,\n",
       "       0.0147349 , 0.02118875, 0.02857728, 0.01016651, 0.05090683,\n",
       "       0.01372365, 0.03660599, 0.00790288, 0.00526411, 0.00874456,\n",
       "       0.04947965, 0.03610237, 0.03693628, 0.02303535, 0.03643664,\n",
       "       0.0261518 , 0.02953481, 0.04898744, 0.04604057, 0.04856355,\n",
       "       0.04614813, 0.02448507, 0.0076965 , 0.01953642, 0.0195496 ,\n",
       "       0.03235822, 0.01406732, 0.00820882, 0.0225564 , 0.02199351,\n",
       "       0.03769882, 0.00972995, 0.02027183, 0.01230977, 0.02994609,\n",
       "       0.01053608, 0.01351084, 0.00704724, 0.02611434, 0.03285315,\n",
       "       0.00642507, 0.02873804, 0.02514421, 0.02876549, 0.01484247,\n",
       "       0.07965027, 0.01298506, 0.01388477, 0.05710039, 0.03096531,\n",
       "       0.01237692, 0.03923709, 0.00651821, 0.03308656, 0.01175814,\n",
       "       0.02695727, 0.03414357, 0.01109122, 0.00843236, 0.02137891,\n",
       "       0.00792998, 0.04435292, 0.02132082, 0.01393903, 0.01253515,\n",
       "       0.00933745, 0.0281544 , 0.03629965, 0.03291992, 0.03090948,\n",
       "       0.02211365, 0.0285456 , 0.01325875, 0.04323608, 0.03964788,\n",
       "       0.02895484, 0.04352331, 0.01983689, 0.05802189, 0.02414636,\n",
       "       0.05244457, 0.02887833, 0.0260423 , 0.04539972, 0.02863083,\n",
       "       0.02951377, 0.05675955, 0.01963055, 0.02498487, 0.01554526,\n",
       "       0.0206384 , 0.01648032, 0.01425061, 0.03802863, 0.03899992,\n",
       "       0.01771244, 0.0491545 , 0.01266439, 0.01235858, 0.00542084,\n",
       "       0.03586324, 0.05548745, 0.03499153, 0.00876738, 0.0353653 ,\n",
       "       0.01220004, 0.01450365, 0.04143132, 0.01694817, 0.02040605,\n",
       "       0.05025063, 0.03830056, 0.02037323, 0.02973897, 0.0197885 ,\n",
       "       0.0330387 , 0.01901111, 0.04487797, 0.00945739, 0.03998091,\n",
       "       0.00521346, 0.04627536, 0.03339115, 0.01485658, 0.01177684,\n",
       "       0.02963791, 0.01780882, 0.02026047, 0.04461427, 0.01742069,\n",
       "       0.01411655, 0.05538242, 0.04180992, 0.01792   , 0.01227632,\n",
       "       0.0170547 , 0.02101506, 0.03097136, 0.00866732, 0.0429327 ,\n",
       "       0.00919735, 0.02794747, 0.03041153, 0.05633624, 0.0348197 ,\n",
       "       0.03258249, 0.0458461 , 0.07899036, 0.01090278, 0.02478948,\n",
       "       0.03212563, 0.00742608, 0.01681873, 0.05179647, 0.01171472,\n",
       "       0.0309245 , 0.03172141, 0.01434639, 0.0266454 , 0.03943634,\n",
       "       0.05410497, 0.02705427, 0.04947849, 0.02057966, 0.04277741,\n",
       "       0.01783368, 0.02093899, 0.00472102, 0.03685193, 0.01225615,\n",
       "       0.00911882, 0.06073083, 0.04134016, 0.00482637, 0.04986417,\n",
       "       0.02612185, 0.0313742 , 0.01006227, 0.0141869 , 0.01644443,\n",
       "       0.02656722, 0.03017103, 0.01914539, 0.01924624, 0.02169641,\n",
       "       0.01471276, 0.04397827, 0.03159455, 0.00648177, 0.02676101,\n",
       "       0.01529693, 0.00836727, 0.04588591, 0.04413346, 0.01758544,\n",
       "       0.01945287, 0.02358602, 0.03865455, 0.03520139, 0.02835436,\n",
       "       0.04822255, 0.04671172, 0.03263644, 0.0257818 , 0.03928299,\n",
       "       0.02371555, 0.02659224, 0.01891628, 0.01659222, 0.01048075,\n",
       "       0.03221534, 0.01012006, 0.01898954, 0.01973113, 0.04702689,\n",
       "       0.02653201, 0.00740274, 0.01094572, 0.02488634, 0.01555994,\n",
       "       0.02368246, 0.02920397, 0.03977186, 0.01345261, 0.02625385,\n",
       "       0.06842434, 0.01663518, 0.02309974, 0.01407197, 0.04656456,\n",
       "       0.01407741, 0.03498098, 0.02899515, 0.03823231, 0.01826083,\n",
       "       0.01334444, 0.02089554, 0.01166274, 0.0407719 , 0.01045345,\n",
       "       0.01324528, 0.0258671 , 0.02850104, 0.01287405, 0.0260741 ,\n",
       "       0.01085609, 0.01160357, 0.02740954, 0.02052881, 0.01227607,\n",
       "       0.01593851, 0.01574352, 0.0422232 , 0.00762808, 0.00757602,\n",
       "       0.01178445, 0.04063872, 0.00890169, 0.01885   , 0.03456429,\n",
       "       0.0318311 , 0.00793838, 0.02674532, 0.05347614, 0.01053202,\n",
       "       0.01580319, 0.00584158, 0.02179665, 0.05991424, 0.10588679,\n",
       "       0.07569163, 0.0811267 , 0.05669462, 0.07311475, 0.06309631,\n",
       "       0.0774721 , 0.06891941, 0.04075722, 0.04482225, 0.04119633,\n",
       "       0.07226531, 0.07072276, 0.08872216, 0.05417018, 0.04820847,\n",
       "       0.06337685, 0.04115787, 0.0138595 , 0.02074212, 0.01909716,\n",
       "       0.03018482, 0.02975208, 0.01562668, 0.03197549, 0.00946578,\n",
       "       0.01843499, 0.02721423, 0.01573313, 0.0564693 , 0.02371189,\n",
       "       0.00700627, 0.03338463, 0.01247023, 0.01141865, 0.04692826,\n",
       "       0.06456558, 0.08575016, 0.01432151, 0.02432459, 0.00834043,\n",
       "       0.03536716, 0.04865041, 0.04785293, 0.05724897, 0.00466627,\n",
       "       0.0285978 , 0.01565873, 0.09942384, 0.03957592, 0.02559586,\n",
       "       0.02570249, 0.05188528, 0.03418547, 0.01692508, 0.02856975,\n",
       "       0.0150971 , 0.04906676, 0.04721046, 0.02574853, 0.04107646,\n",
       "       0.00925933, 0.04722117, 0.0430389 , 0.03111999, 0.01345358,\n",
       "       0.01183952, 0.02886475, 0.01251185, 0.03941836, 0.02172883,\n",
       "       0.04832246, 0.03364472, 0.08354971, 0.05379016, 0.05706092],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.stripped_model.summary()\n",
    "ae.stripped_model.predict(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tensorflow/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/tensorflow/1/assets\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"./models/tensorflow\", exist_ok=True)\n",
    "\n",
    "model_path = \"./models/tensorflow/1/\"\n",
    "tf.saved_model.save(ae.stripped_model, model_path)\n",
    "\n",
    "# We could save the full model, by referencing ae.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-examples-EfRPkUGI-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
